# -----------------------------------------------------------------------------
# Copyright (c) 2019, Battelle National Biodefense Institute.
#
# This file is part of MicroHapDB (http://github.com/bioforensics/microhapdb)
# and is licensed under the BSD license: see LICENSE.txt.
# -----------------------------------------------------------------------------


from glob import glob
import os
import pandas


def load_source_data(table, source):
    src = source.read().strip()
    data = pandas.read_csv(table, sep='\t', index_col=None)
    data['Source'] = src
    return data


def write_variant_map(data, output):
    print('Variant', 'Marker', sep='\t', file=output)
    for n, row in data.iterrows():
        marker = row['Name']
        for variant in row['VarRef'].split(','):
            print(variant, marker, sep='\t', file=output)


SOURCES = [os.path.basename(file) for file in glob('sources/*') if os.path.isdir(file)]


rule tables:
    input:
        expand('{table}.tsv', table=['marker', 'population', 'frequency', 'idmap', 'variantmap'])


rule populations:
    input:
        expand('sources/{source}/population.tsv', source=SOURCES),
        expand('sources/{source}/source.txt', source=SOURCES),
    output:
        table='population.tsv'
    run:
        numsources = int(len(input) / 2)
        popfiles = input[:numsources]
        sourcefiles = input[numsources:]

        dfs = list()
        for popfile, sourcefile in zip(popfiles, sourcefiles):
            with open(sourcefile, 'r') as fh:
                df = load_source_data(popfile, fh)
                dfs.append(df)
        data = pandas.concat(dfs, axis=0, ignore_index=True)
        data.sort_values('Name').to_csv(output.table, sep='\t', index=False)


rule markers:
    input:
        expand('sources/{source}/marker.tsv', source=SOURCES),
        expand('sources/{source}/source.txt', source=SOURCES),
    output:
        table='marker.tsv',
        varmap='variantmap.tsv'
    run:
        numsources = int(len(input) / 2)
        markerfiles = input[:numsources]
        sourcefiles = input[numsources:]

        dfs = list()
        for markerfile, sourcefile in zip(markerfiles, sourcefiles):
            with open(sourcefile, 'r') as fh:
                df = load_source_data(markerfile, fh)
                dfs.append(df)

        data = pandas.concat(dfs, axis=0, ignore_index=True)
        with open(output.varmap, 'w') as fh:
            write_variant_map(data, fh)

        data.drop(columns=['Xref', 'VarRef'], inplace=True)
        data.to_csv(output.table, sep='\t', index=False)
