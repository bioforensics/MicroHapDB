# -----------------------------------------------------------------------------
# Copyright (c) 2018, Battelle National Biodefense Institute.
#
# This file is part of MicroHapDB (http://github.com/bioforensics/microhapdb)
# and is licensed under the BSD license: see LICENSE.txt.
# -----------------------------------------------------------------------------

# Import from standard libraries
from hashlib import sha1
from os import chmod
from urllib.request import urlretrieve

# Import from internal libraries
from allele import allele_frequencies
from files import sopen, download_and_compress, cat, dlfile, tmpfile
from locus import locus_list, locus_scrape, combine_locus_data, ALL_LOCI
from population import population_summary
from variant import variant_xref, combine_variants


rule tables:
    input: expand('{datatype}.tsv', datatype=['allele', 'locus', 'population', 'variant'])
    output: 'tables.complete'
    run:
        with open(output[0], 'w') as outfile:
            print('Done', file=outfile)


# -----------------------------------------------------------------------------
# Downloads
# -----------------------------------------------------------------------------

rule mhafdb:
    """Download microhap allele frequency database from ALFRED."""
    output: protected(dlfile('Microhap_alleleF.txt'))
    run:
        url = 'https://alfred.med.yale.edu/alfred/selectDownload/Microhap_alleleF.txt'
        urlretrieve(url, output[0])
        with open(output[0], 'r') as filetocheck:
            sha = sha1(filetocheck.read().encode('utf-8')).hexdigest()
            assert sha == 'b13d8a9d197149d65f1c6c2a34100a6b0686bc28'
        # os.chmod(output[0], 0o444)


rule locusdetail:
    input: tmpfile('microhap-loci-prelim.tsv')
    output: protected(dlfile('locus-detail/{locus}.html.gz'))
    run:
        url = "https://alfred.med.yale.edu/alfred/recordinfo.asp?condition=sites.site_uid='" + wildcards.locus
        download_and_compress(url, output[0])
        # os.chmod(output[0], 0o444)


rule fetchallloci:
    input: expand(dlfile('locus-detail/{locus}.html.gz'), locus=ALL_LOCI)
    output: dlfile('fetchallloci.complete')
    run:
        with open(output[0], 'w') as outfile:
            print('Done', file=outfile)


# -----------------------------------------------------------------------------
# Alleles
# -----------------------------------------------------------------------------

rule all_alleles:
    """Aggregate all microhap locus allele data."""
    input: expand(tmpfile('locus-alleles/{locus}.tsv.gz'), locus=ALL_LOCI)
    output: tmpfile('locus-alleles-all.tsv')
    run:
        with open(output[0], 'w') as outstream:
            print('Locus', 'Allele', 'Variants', sep='\t', file=outstream)
            cat(outstream, input)


rule allelefreq:
    """Format allele frequency data."""
    input:
        dlfile('Microhap_alleleF.txt'),
        'indel-alleles.json'
    output:
        'allele.tsv',
        'allele-mismatch.log'
    run:
        with open(output[0], 'w') as outstream, open(output[1], 'w') as logstream:
            print('Locus', 'Population', 'Allele', 'Frequency', sep='\t', file=outstream)
            for af in allele_frequencies(input[0], input[1], logstream):
                print(af.locusid, af.popid, af.allele, af.freq, sep='\t', file=outstream)


# -----------------------------------------------------------------------------
# Loci
# -----------------------------------------------------------------------------

rule listloci:
    input: dlfile('Microhap_alleleF.txt')
    output: tmpfile('microhap-loci-prelim.tsv')
    run:
        with sopen(input[0], 'r') as instream, sopen(output[0], 'w') as outstream:
            print('ID', 'Name', sep='\t', file=outstream)
            for locusid, locusname in locus_list(instream):
                print(locusid, locusname, sep='\t', file=outstream)


rule scrapelocus:
    input: ancient(dlfile('locus-detail/{locus}.html.gz'))
    output:
        tmpfile('locus-variants/{locus}.tsv.gz'),
        tmpfile('locus-alleles/{locus}.tsv.gz')
    run:
        with sopen(input[0], 'r') as instream:
            locus_scrape(wildcards.locus, instream, output[1], output[0])


rule combine_loci:
    input:
        tmpfile('microhap-loci-prelim.tsv'),
        tmpfile('locus-alleles-all.tsv'),
        'variant.tsv'
    output: 'locus.tsv'
    run:
        with sopen(input[0], 'r') as idstream, sopen(input[1], 'r') as allelestream, sopen(input[2], 'r') as variantstream, sopen(output[0], 'w') as outstream:
            print('ID', 'Name', 'Chrom', 'Start', 'End', 'Variants', sep='\t', file=outstream)
            for locus in combine_locus_data(idstream, allelestream, variantstream):
                print(locus.locusid, locus.locusname, locus.chrom, locus.start, locus.end, locus.variants, sep='\t', file=outstream)


# -----------------------------------------------------------------------------
# Populations
# -----------------------------------------------------------------------------

rule population:
    input: dlfile('Microhap_alleleF.txt')
    output: 'population.tsv'
    run:
        with sopen(input[0], 'r') as instream, sopen(output[0], 'w') as outstream:
            print('ID', 'Name', 'NumChrom', sep='\t', file=outstream)
            for pop in population_summary(instream):
                print(pop.popid, pop.popname, pop.numchrom, sep='\t', file=outstream)


# -----------------------------------------------------------------------------
# Variants
# -----------------------------------------------------------------------------

rule all_variants:
    """Aggregate all microhap locus variant data."""
    input: expand(tmpfile('locus-variants/{locus}.tsv.gz'), locus=ALL_LOCI)
    output: tmpfile('locus-variants-all.tsv')
    run:
        with open(output[0], 'w') as outstream:
            print('Locus', 'dbSNPID', 'AlfredID', 'Reference', 'Alternate', sep='\t', file=outstream)
            cat(outstream, input)


rule parse_variant_data:
    input:
        config['dbsnp'],
        tmpfile('locus-variants-all.tsv')
    output: tmpfile('variant-data.tsv')
    run:
        with sopen(output[0], 'w') as outstream, sopen(input[0], 'r') as dbsnp, sopen(input[1], 'r') as alfred:
            print('dbSNPID', 'Chrom', 'Position', 'Reference', 'Alternate', sep='\t', file=outstream)
            for v in variant_xref(alfred, dbsnp):
                print(v.dbsnpid, v.chrom, v.position, v.refr, v.alt, sep='\t', file=outstream)


rule combine_variants:
    input:
        tmpfile('locus-variants-all.tsv'),
        tmpfile('variant-data.tsv')
    output:
        'variant.tsv'
    run:
        with open(input[0], 'r') as alfred, open(input[1], 'r') as dbsnp, open(output[0], 'w') as outstream:
            print('ID', 'AlfredID', 'Chrom', 'Start', 'End', 'AlfredAlleles', 'dbSNPAlleles', sep='\t', file=outstream)
            for v in combine_variants(alfred, dbsnp):
                print(v.dbsnpid, v.alfredid, v.chrom, v.start, v.end, v.alfalleles, v.dbsnpalleles, sep='\t', file=outstream)
