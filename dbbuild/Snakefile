# -----------------------------------------------------------------------------
# Copyright (c) 2018, Battelle National Biodefense Institute.
#
# This file is part of MicroHapDB (http://github.com/bioforensics/microhapdb)
# and is licensed under the BSD license: see LICENSE.txt.
# -----------------------------------------------------------------------------

# Import from standard libraries
from gzip import open as gzopen
from hashlib import sha1
from os import chmod
from urllib.request import urlretrieve

import pandas

# Import from internal libraries
from allele import allele_frequencies_alfred, allele_frequencies_lovd, allele_frequencies_linköping
from files import smartopen
from locus import alfred_locus_list, alfred_loci_prelim, lovd_loci_prelim, linköping_loci_prelim, combine_loci
from locus import alfred_locus_scrape
from population import population_summary
from variant import dbsnp_subset_command, retrieve_proximal_variants


ALL_ALFRED_LOCI = list()
with smartopen('alfred/Microhap_alleleF_198.txt', 'r') as instream:
    for locusid, locusname in alfred_locus_list(instream):
        ALL_ALFRED_LOCI.append(locusid)


rule tables:
    input:
        expand('{table}.tsv', table=['allele', 'marker', 'population', 'variant', 'idmap', 'variantmap'])


# -----------------------------------------------------------------------------
# Loci
# -----------------------------------------------------------------------------


rule scrapelocus:
    input: 'alfred/downloads/locus-detail/{locus}.html.gz'
    output:
        'intermediate/locus-variants/{locus}.tsv.gz',
        'intermediate/locus-alleles/{locus}.tsv.gz'
    run:
        with smartopen(input[0], 'r') as instream:
            alfred_locus_scrape(wildcards.locus, instream, output[1], output[0])


rule alfred_loci_prelim:
    input:
        'alfred/Microhap_alleleF_198.txt',
        'alfred/curated/alfred-microhap-coords-hg38.tsv'
    output: 'intermediate/alfred-loci.tsv'
    run:
        with smartopen(input[0], 'r') as freqinput, smartopen(input[1], 'r') as coordinput, smartopen(output[0], 'w') as outstream:
            print('Chrom', 'Start', 'End', 'Source', 'AlfredID', 'AlfredName', sep='\t', file=outstream)
            for values in alfred_loci_prelim(freqinput, coordinput):
                print(*values, sep='\t', file=outstream)


rule lovd_loci_prelim:
    input: 'lovd/lovd-microhap-loci.txt'
    output: 'intermediate/lovd-loci.tsv'
    run:
        with smartopen(input[0], 'r') as instream, smartopen(output[0], 'w') as outstream:
            print('Chrom', 'Start', 'End', 'Source', 'LovdID', sep='\t', file=outstream)
            for values in lovd_loci_prelim(instream):
                print(*values, sep='\t', file=outstream)


rule linköping_loci_prelim:
    input:
        'linkoping/microhap-definitions.tsv',
        'linkoping/snps-GRCh38.vcf.gz'
    output: 'intermediate/linköping-loci.tsv'
    run:
        with smartopen(input[0], 'r') as defstream, smartopen(input[1], 'r') as varstream, smartopen(output[0], 'w') as outstream:
            print('Chrom', 'Start', 'End', 'Source', 'Label', file=outstream)
            for values in linköping_loci_prelim(defstream, varstream):
                print(*values, sep='\t', file=outstream)


rule combine_loci:
    input:
        'intermediate/alfred-loci.tsv',
        'intermediate/lovd-loci.tsv',
        'intermediate/linköping-loci.tsv'
    output:
        'intermediate/locus-prelim.tsv',
        'intermediate/locusids.tsv.gz'
    run:
        with smartopen(input[0], 'r') as alfredstream, smartopen(input[1], 'r') as lovdstream, smartopen(input[2], 'r') as linkstream, smartopen(output[0], 'w') as outstream, smartopen(output[1], 'w') as idstream:
            print('ID', 'Reference', 'Chrom', 'Start', 'End', 'Source', sep='\t', file=outstream)
            for values in combine_loci(alfredstream, lovdstream, linkstream):
                fp = idstream if len(values) == 3 else outstream
                print(*values, sep='\t', file=fp)


rule score_loci:
    input:
        'intermediate/locus-prelim.tsv',
        'allele.tsv'
    output:
        'marker.tsv'
    run:
        loci = pandas.read_table(input[0])
        freqs = pandas.read_table(input[1])
        aes = list()
        for n, locusid in enumerate(loci['ID']):
            if n > 0 and n % 10 == 0:
                print('....processed', n, 'loci')
            ae_per_pop = list()
            for pop in freqs[freqs.Marker == locusid].Population.unique():
                ae_recip = 0.0
                for freq in freqs[(freqs.Marker == locusid) & (freqs.Population == pop)].Frequency:
                    ae_recip += freq ** 2
                ae = 1.0 / ae_recip
                ae_per_pop.append(ae)
            avg_ae = sum(ae_per_pop) / len(ae_per_pop)
            aes.append('{:.04f}'.format(avg_ae))
        loci = loci.assign(AvgAe=pandas.Series(aes))
        column_order = ['ID', 'Reference', 'Chrom', 'Start', 'End', 'AvgAe',
                        'Source']
        loci = loci[column_order]
        loci.to_csv(output[0], sep='\t', index=False)


# -----------------------------------------------------------------------------
# Populations
# -----------------------------------------------------------------------------

rule population:
    input:
        'alfred/Microhap_alleleF_198.txt',
        'lovd/pops.tsv'
    output:
        'population.tsv',
        'intermediate/popids.tsv.gz'
    run:
        with smartopen(input[0], 'r') as alfredstream, smartopen(input[1], 'r') as lovdstream, smartopen(output[0], 'w') as outstream, smartopen(output[1], 'w') as idstream:
            print('ID', 'Name', 'Source', sep='\t', file=outstream)
            for popid, poplabel, popname, source in population_summary(alfredstream, lovdstream):
                print(popid, popname, source, sep='\t', file=outstream)
                print(poplabel, 'population', popid, sep='\t', file=idstream)


# -----------------------------------------------------------------------------
# Variants
# -----------------------------------------------------------------------------


rule dbsnp_subset:
    input:
        'intermediate/locus-prelim.tsv',
        config['dbsnp']
    output: 'intermediate/dbsnp-subset.vcf'
    run:
        cmd = dbsnp_subset_command(*input, *output)
        shell(cmd)


rule locus_variants:
    """Aggregate all microhap locus variant data."""
    input: expand('intermediate/locus-variants/{locus}.tsv.gz', locus=ALL_ALFRED_LOCI)
    output: 'intermediate/alfred-variants-all.tsv'
    run:
        with smartopen(output[0], 'w') as outstream:
            print('Locus', 'dbSNPID', 'AlfredID', 'Reference', 'Alternate', sep='\t', file=outstream)
        shell('gunzip -c {input} >> {output}')


rule parse_variant_data:
    input:
        'intermediate/dbsnp-subset.vcf',
        'intermediate/alfred-variants-all.tsv',
        'lovd/lovd-microhap-variants.tsv',
        'linkoping/linkoping-microhap-variants.tsv',
        'intermediate/locusids.tsv.gz'
    output:
        'variant.tsv',
        'variantmap.tsv',
        'intermediate/varids.tsv.gz',
    run:
        with smartopen(output[0], 'w') as variantstream, smartopen(output[1], 'w') as varmap, smartopen(output[2], 'w') as varidstream, smartopen(input[0], 'r') as dbsnp, smartopen(input[1], 'r') as alfred, smartopen(input[2], 'r') as lovd, smartopen(input[3], 'r') as linkoping, smartopen(input[4], 'r') as locusids:
            locus_ids = dict()
            for line in locusids:
                xref, table, lid = line.strip().split()
                locus_ids[xref] = lid

            print('ID', 'Reference', 'Chrom', 'Position', 'Alleles', 'Source', sep='\t', file=variantstream)
            print('LocusID', 'VariantID', sep='\t', file=varmap)
            for n, v in enumerate(retrieve_proximal_variants(dbsnp, alfred, lovd, linkoping), 1):
                varid = 'MHDBV{:09d}'.format(n)
                print(varid, 'GRCh38', v.chrom, v.pos, v.alleles, v.source, sep='\t', file=variantstream)
                if v.dbsnpid is not None:
                    print(v.dbsnpid, 'variant', varid, sep='\t', file=varidstream)
                if v.xref is not None:
                    print(v.xref, 'variant', varid, sep='\t', file=varidstream)
                if v.markerlabel is not None:
                    locusid = locus_ids[v.markerlabel]
                    print(locusid, varid, sep='\t', file=varmap)


# -----------------------------------------------------------------------------
# ID mapping
# -----------------------------------------------------------------------------

rule idmap:
    input: expand('intermediate/{table}.tsv.gz', table=['popids', 'locusids', 'varids'])
    output: 'idmap.tsv'
    run:
        with smartopen(output[0], 'w') as outstream:
            print('XRef', 'Table', 'mhdbID', sep='\t', file=outstream)
        shell('gunzip -c {input} >> {output}')


# -----------------------------------------------------------------------------
# Alleles
# -----------------------------------------------------------------------------

rule allelefreq:
    """Format allele frequency data."""
    input:
        'alfred/Microhap_alleleF_198.txt',
        'alfred/curated/indel-alleles.json',
        'lovd/lovd-microhap-loci.txt',
        'lovd/lovd-allele-frequencies.txt',
        'linkoping/microhap-definitions.tsv',
        'linkoping/microhap-frequencies.tsv',
        'idmap.tsv'
    output: 'allele.tsv'
    run:
        with smartopen(output[0], 'w') as outstream, smartopen(input[6], 'r') as instream:
            mapping = dict()
            for line in instream:
                values = line.strip().split()
                mapping[values[0]] = values[2]
            print('Marker', 'Population', 'Allele', 'Frequency', sep='\t', file=outstream)
            for af in allele_frequencies_alfred(input[0], input[1]):
                print(mapping[af.locusid], mapping[af.popid], af.allele, af.freq, sep='\t', file=outstream)
            for af in allele_frequencies_lovd(input[2], input[3]):
                print(mapping[af.locusid], mapping[af.popid], af.allele, af.freq, sep='\t', file=outstream)
            for af in allele_frequencies_linköping(input[4], input[5]):
                print(mapping[af.locusid], mapping[af.popid], af.allele, af.freq, sep='\t', file=outstream)
